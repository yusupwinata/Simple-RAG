{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aebb5b46-576b-40dd-a599-3ff6ede67c2e",
   "metadata": {},
   "source": [
    "# Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8db38361-5cff-43de-b7df-6932a0961843",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import gradio as gr\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97b0633f-6644-49a1-8bb7-3c7f588fedf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API creds\n",
    "load_dotenv(override=True)\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"type-your-api-key-here\")\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\", \"type-your-api-key-here\")\n",
    "OLLAMA_API_KEY = \"ollama\"\n",
    "\n",
    "GOOGLE_BASE_URL = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434/v1\"\n",
    "\n",
    "client_openai = OpenAI()\n",
    "client_google = OpenAI(api_key=GOOGLE_API_KEY, base_url=GOOGLE_BASE_URL)\n",
    "client_ollama = OpenAI(api_key=OLLAMA_API_KEY, base_url=OLLAMA_BASE_URL)\n",
    "\n",
    "# Models\n",
    "gpt = \"gpt-4o-mini\"\n",
    "gemini = \"models/gemini-2.0-flash\"\n",
    "llama = \"llama3.2:latest\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d55a148-08a9-4cb5-af52-284d62a37aa1",
   "metadata": {},
   "source": [
    "# Build Context from Knowledge Base (KB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ac73551-0129-461e-b931-b204fec1503f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "ABSOLUTE_PATH = os.path.abspath(os.getcwd())\n",
    "KB_PATH = os.path.join(ABSOLUTE_PATH, \"knowledge-base-nexatech\")\n",
    "\n",
    "def set_path(dir_name: str, kb_path: str=KB_PATH) -> str:\n",
    "    return os.path.join(KB_PATH, dir_name)\n",
    "\n",
    "COMPANY_DATA_PATH = set_path(\"company\")\n",
    "PRODUCT_DATA_PATH = set_path(\"products\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c528f30f-439e-4084-984f-99c2b3e29dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['about', 'careers', 'overview', 'CustomerVault CRM', 'DataMind Analytics', 'ProjectFlow Pro', 'TeamSync Hub'])\n"
     ]
    }
   ],
   "source": [
    "def get_file_name(file_path: str) -> str:\n",
    "    \"\"\"Get file name without extension format\"\"\"\n",
    "    return Path(os.path.basename(file_path)).stem\n",
    "\n",
    "def get_file_content(file_path: str) -> str:\n",
    "    \"\"\"Get file content\"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read()\n",
    "    return content\n",
    "\n",
    "context = {}\n",
    "\n",
    "# Get company data\n",
    "company_info = glob.glob(COMPANY_DATA_PATH + \"/*\" + \".md\") # get all .md files\n",
    "for info in company_info:\n",
    "    title = get_file_name(info)\n",
    "    context[title] = get_file_content(info)\n",
    "\n",
    "# Get product data\n",
    "products = glob.glob(PRODUCT_DATA_PATH + \"/*\" + \".md\")\n",
    "for product in products:\n",
    "    prod_name = get_file_name(product)\n",
    "    context[prod_name] = get_file_content(product)\n",
    "\n",
    "print(context.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f2533c-f8a8-4a33-96c1-8486e2cf1e51",
   "metadata": {},
   "source": [
    "# Simple RAG (Retrieval-Augmented Generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "279cad4e-c82b-48b0-9a05-3118f3f872b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_relevant_context(message: str) -> list:\n",
    "    \"Get relevant context based on input message\"\n",
    "    relevant_context = []\n",
    "    for context_title, context_details in context.items():\n",
    "        if context_title in message or context_title.lower() in message:\n",
    "            relevant_context.append(context_details)\n",
    "    return relevant_context\n",
    "\n",
    "# Testing\n",
    "test = get_relevant_context(\"Tell me about spencer and datamind analytics\")\n",
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "558ac32a-c3c9-44f5-9379-81baf3521163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tell me about datamind analytics\n",
      "\n",
      "The following additional context might be relevant in answering this question:\n",
      "\n",
      "Company Profile\n",
      "NexaTech Solutions i\n"
     ]
    }
   ],
   "source": [
    "def add_context(message: str) -> str:\n",
    "    \"\"\"Add relevant context to input messages\"\"\"\n",
    "    relevant_context = get_relevant_context(message)\n",
    "    if not relevant_context:\n",
    "        return message\n",
    "    \n",
    "    message += \"\\n\\nThe following additional context might be relevant in answering this question:\\n\\n\"\n",
    "    message += \"\\n\\n\".join(relevant_context)\n",
    "\n",
    "    return message\n",
    "\n",
    "# Testing\n",
    "test = add_context(\"Tell me about datamind analytics\")\n",
    "print(test[:150])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655c013e-55a4-407b-ae4b-95e9811be1c9",
   "metadata": {},
   "source": [
    "# Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47f169c0-c2b9-4de1-b8fe-22f3b3499f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are a specialist in providing precise and reliable information about NexaTech Solutions \\\n",
    "â€” a company offering cloud-based enterprise solutions and AI-driven business tools. \\\n",
    "Keep your answers concise and factual. If you lack the necessary context to answer, state that clearly. \\\n",
    "Do not fabricate any information.\"\n",
    "\n",
    "def chat(message, history, client: OpenAI=client_ollama, model: str=llama):\n",
    "    \"\"\"Dedicated Gradio function for chatbot\"\"\"\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history\n",
    "    \n",
    "    # Add context using simple RAG\n",
    "    message = add_context(message)\n",
    "    messages.append({\"role\": \"user\", \"content\": message})\n",
    "\n",
    "    # Generate response\n",
    "    stream = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0.8,\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or \"\"\n",
    "        yield response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74dcee4c-3568-40aa-8825-f44e0cc9d461",
   "metadata": {},
   "source": [
    "# UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f454424-1ddf-40fb-bca2-824c22b00555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7905\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7905/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view = gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df624c6-b6ed-4438-bf62-92d61e4b7d05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hugface",
   "language": "python",
   "name": "hugface"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
